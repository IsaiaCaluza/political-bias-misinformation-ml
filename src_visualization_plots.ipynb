{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgvEcj2vzJ8i"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, display_labels=None, title=\"Confusion Matrix\", cmap=\"Blues\"):\n",
        "    \"\"\"\n",
        "    Plot confusion matrix for classifier evaluation.\n",
        "\n",
        "    Args:\n",
        "        y_true: True labels\n",
        "        y_pred: Predicted labels\n",
        "        display_labels (list): Label names for display\n",
        "        title (str): Plot title\n",
        "        cmap (str): Colormap for the plot\n",
        "\n",
        "    Returns:\n",
        "        matplotlib.figure.Figure: The figure object containing the plot\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=display_labels)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "    disp.plot(cmap=cmap, ax=ax)\n",
        "    plt.title(title)\n",
        "\n",
        "    return fig\n",
        "\n",
        "def plot_roc_curves(y_true, model_probabilities, class_names=None, title=\"ROC Curves\"):\n",
        "    \"\"\"\n",
        "    Plot ROC curves for multi-class classification.\n",
        "\n",
        "    Args:\n",
        "        y_true: True labels\n",
        "        model_probabilities (dict): Dictionary with model names as keys and prediction probabilities as values\n",
        "        class_names (list): Names of the classes\n",
        "        title (str): Plot title\n",
        "\n",
        "    Returns:\n",
        "        matplotlib.figure.Figure: The figure object containing the plot\n",
        "    \"\"\"\n",
        "    if class_names is None:\n",
        "        class_names = [f\"Class {i}\" for i in range(len(np.unique(y_true)))]\n",
        "\n",
        "    n_classes = len(class_names)\n",
        "\n",
        "    # Binarize the labels for ROC calculation\n",
        "    y_true_bin = label_binarize(y_true, classes=range(n_classes))\n",
        "\n",
        "    # Create figure\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    # Define colors for different classes\n",
        "    colors = ['red', 'green', 'blue']\n",
        "\n",
        "    # Calculate and plot ROC curves for each model and class\n",
        "    for model_name, probs in model_probabilities.items():\n",
        "        linestyle = '--' if 'DNN' in model_name else '-'\n",
        "\n",
        "        for i in range(n_classes):\n",
        "            fpr, tpr, _ = roc_curve(y_true_bin[:, i], probs[:, i])\n",
        "            roc_auc = auc(fpr, tpr)\n",
        "            ax.plot(\n",
        "                fpr, tpr, linestyle=linestyle, color=colors[i],\n",
        "                label=f'{model_name} - {class_names[i]} (AUC = {roc_auc:.2f})'\n",
        "            )\n",
        "\n",
        "    # Add diagonal line (random classifier)\n",
        "    ax.plot([0, 1], [0, 1], 'k--')\n",
        "\n",
        "    # Customize plot\n",
        "    ax.set_xlabel(\"False Positive Rate\")\n",
        "    ax.set_ylabel(\"True Positive Rate\")\n",
        "    ax.set_title(title)\n",
        "    ax.legend(loc=\"lower right\")\n",
        "    ax.grid(True)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return fig\n",
        "\n",
        "def plot_training_history(history, title=\"Training History\"):\n",
        "    \"\"\"\n",
        "    Plot training and validation metrics from model training history.\n",
        "\n",
        "    Args:\n",
        "        history (dict): Training history dictionary\n",
        "        title (str): Plot title\n",
        "\n",
        "    Returns:\n",
        "        matplotlib.figure.Figure: The figure object containing the plot\n",
        "    \"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "    # Plot accuracy\n",
        "    if 'accuracy' in history:\n",
        "        ax1.plot(history['accuracy'], label='Training Accuracy')\n",
        "    if 'val_accuracy' in history:\n",
        "        ax1.plot(history['val_accuracy'], label='Validation Accuracy')\n",
        "\n",
        "    ax1.set_title('Model Accuracy')\n",
        "    ax1.set_ylabel('Accuracy')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True)\n",
        "\n",
        "    # Plot loss\n",
        "    if 'loss' in history:\n",
        "        ax2.plot(history['loss'], label='Training Loss')\n",
        "    if 'val_loss' in history:\n",
        "        ax2.plot(history['val_loss'], label='Validation Loss')\n",
        "\n",
        "    ax2.set_title('Model Loss')\n",
        "    ax2.set_ylabel('Loss')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True)\n",
        "\n",
        "    plt.suptitle(title)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return fig\n",
        "\n",
        "def plot_wordcloud_by_cluster(texts_by_cluster, title_prefix=\"Cluster\", figsize=(15, 10)):\n",
        "    \"\"\"\n",
        "    Generate wordclouds for text clusters.\n",
        "\n",
        "    Args:\n",
        "        texts_by_cluster (dict): Dictionary with cluster IDs as keys and concatenated texts as values\n",
        "        title_prefix (str): Prefix for subplot titles\n",
        "        figsize (tuple): Figure size\n",
        "\n",
        "    Returns:\n",
        "        matplotlib.figure.Figure: The figure object containing the wordclouds\n",
        "    \"\"\"\n",
        "    num_clusters = len(texts_by_cluster)\n",
        "    fig, axes = plt.subplots(1, num_clusters, figsize=figsize)\n",
        "\n",
        "    # Handle the case with only one cluster\n",
        "    if num_clusters == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    for i, (cluster_id, text) in enumerate(texts_by_cluster.items()):\n",
        "        # Create TF-IDF vectorizer\n",
        "        vectorizer = TfidfVectorizer(stop_words='english', max_features=100)\n",
        "        tfidf_matrix = vectorizer.fit_transform([text])\n",
        "\n",
        "        # Get top words and their scores\n",
        "        feature_names = vectorizer.get_feature_names_out()\n",
        "        tfidf_scores = tfidf_matrix.toarray().flatten()\n",
        "        word_scores = {feature_names[j]: tfidf_scores[j] for j in range(len(feature_names))}\n",
        "\n",
        "        # Create wordcloud\n",
        "        wordcloud = WordCloud(width=800, height=400, background_color='white')\n",
        "        wordcloud.generate_from_frequencies(word_scores)\n",
        "\n",
        "        # Plot\n",
        "        axes[i].imshow(wordcloud, interpolation='bilinear')\n",
        "        axes[i].set_title(f\"{title_prefix} {cluster_id}\", fontsize=16)\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def visualize_cluster_distribution(df, cluster_col, label_col, title=\"Cluster Distribution by Label\"):\n",
        "    \"\"\"\n",
        "    Visualize distribution of labels across clusters.\n",
        "\n",
        "    Args:\n",
        "        df (pandas.DataFrame): DataFrame containing cluster and label information\n",
        "        cluster_col (str): Column name for cluster labels\n",
        "        label_col (str): Column name for true labels/classes\n",
        "        title (str): Plot title\n",
        "\n",
        "    Returns:\n",
        "        matplotlib.figure.Figure: The figure object containing the plot\n",
        "    \"\"\"\n",
        "    # Create cross-tabulation of clusters and labels\n",
        "    cross_tab = pd.crosstab(df[cluster_col], df[label_col])\n",
        "\n",
        "    # Normalize by cluster\n",
        "    cross_tab_norm = cross_tab.div(cross_tab.sum(axis=1), axis=0)\n",
        "\n",
        "    # Plot\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
        "\n",
        "    # Raw counts\n",
        "    sns.heatmap(cross_tab, annot=True, cmap=\"YlGnBu\", fmt=\"d\", ax=ax1)\n",
        "    ax1.set_title(\"Raw Counts\")\n",
        "    ax1.set_xlabel(\"True Label\")\n",
        "    ax1.set_ylabel(\"Cluster\")\n",
        "\n",
        "    # Normalized proportions\n",
        "    sns.heatmap(cross_tab_norm, annot=True, cmap=\"YlGnBu\", fmt=\".2f\", ax=ax2)\n",
        "    ax2.set_title(\"Proportions within Clusters\")\n",
        "    ax2.set_xlabel(\"True Label\")\n",
        "    ax2.set_ylabel(\"Cluster\")\n",
        "\n",
        "    plt.suptitle(title, fontsize=16)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return fig\n",
        "\n",
        "def compare_model_performances(results_dict, metric='accuracy', title=\"Model Performance Comparison\"):\n",
        "    \"\"\"\n",
        "    Compare performance metrics across different models.\n",
        "\n",
        "    Args:\n",
        "        results_dict (dict): Dictionary with model names as keys and performance metrics as values\n",
        "        metric (str): Metric to compare ('accuracy', 'precision', 'recall', or 'f1')\n",
        "        title (str): Plot title\n",
        "\n",
        "    Returns:\n",
        "        matplotlib.figure.Figure: The figure object containing the plot\n",
        "    \"\"\"\n",
        "    # Extract metric values\n",
        "    models = list(results_dict.keys())\n",
        "    values = [results_dict[model][metric] for model in models]\n",
        "\n",
        "    # Create figure\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    # Create bar plot\n",
        "    bars = ax.bar(models, values, color=['skyblue', 'lightgreen', 'coral'])\n",
        "\n",
        "    # Add value labels on top of bars\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.text(\n",
        "            bar.get_x() + bar.get_width()/2.,\n",
        "            height + 0.01,\n",
        "            f'{height:.2f}',\n",
        "            ha='center', va='bottom'\n",
        "        )\n",
        "\n",
        "    # Customize plot\n",
        "    ax.set_ylim(0, 1.0)\n",
        "    ax.set_ylabel(f'{metric.capitalize()} Score')\n",
        "    ax.set_title(title)\n",
        "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "    return fig"
      ]
    }
  ]
}